{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd031b91c49bde7e3c6fc9213e05887f777d08744027ab71904dfeec791132a5b07",
   "display_name": "Python 3.8.8 64-bit ('tf-gpu': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "31b91c49bde7e3c6fc9213e05887f777d08744027ab71904dfeec791132a5b07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def encoder_inference(enc_input):\n",
    "    # подготовка запроса\n",
    "    request_data = json.dumps({\n",
    "        \"signature_name\": \"serving_default\",\n",
    "        \"inputs\": {'encoder_input': enc_input.tolist()}\n",
    "    })\n",
    "    headers = {\"content-type\": \"application/json\"}\n",
    "\n",
    "    # HTTP запрос на сервер\n",
    "    json_response = requests.post(\n",
    "        'http://localhost:8501/v1/models/encoder:predict',\n",
    "        data=request_data, headers=headers)\n",
    "\n",
    "    # Обработка JSON ответа\n",
    "    predictions = json.loads(json_response.text)\n",
    "    \n",
    "    if 'predictions' in predictions:\n",
    "        encoder_outputs = predictions['predictions']\n",
    "    elif 'outputs' in predictions:\n",
    "        encoder_outputs = predictions['outputs']\n",
    "    else:\n",
    "        print('Encoder error json:', predictions)\n",
    "    \n",
    "    return encoder_outputs\n",
    "\n",
    "def decoder_inference(dec_input, h_out, c_out, enc_out):\n",
    "    # подготовка запроса\n",
    "    request_data = json.dumps({\n",
    "        \"signature_name\": \"serving_default\",\n",
    "        \"inputs\": {\n",
    "            'decoder_input': dec_input,\n",
    "            'h_input': h_out,\n",
    "            'c_input': c_out,\n",
    "            'encoder_output': enc_out,\n",
    "            }\n",
    "    })\n",
    "    headers = {\"content-type\": \"application/json\"}\n",
    "\n",
    "    # HTTP запрос на сервер\n",
    "    json_response = requests.post(\n",
    "        'http://localhost:8501/v1/models/decoder:predict',\n",
    "        data=request_data, headers=headers)\n",
    "\n",
    "    # Обработка JSON ответа\n",
    "    predictions = json.loads(json_response.text)\n",
    "    if 'predictions' in predictions:\n",
    "        decoder_outputs = predictions['predictions']\n",
    "    elif 'outputs' in predictions:\n",
    "        decoder_outputs = predictions['outputs']\n",
    "    else:\n",
    "        print('Decoder error json:', predictions)\n",
    "\n",
    "    return decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Input vocab size: 17113\nTarget vocab size: 17239\n"
     ]
    }
   ],
   "source": [
    "# load vocab\n",
    "base_dir = './exports/'\n",
    "enc_dir = base_dir + 'encoder/'\n",
    "dec_dir = base_dir + 'decoder/'\n",
    "vocab_dir = base_dir + 'vocabulary/'\n",
    "\n",
    "input_token2idx = np.load(vocab_dir + 'input_token2idx.npy', allow_pickle=True).item()\n",
    "target_token2idx = np.load(vocab_dir + 'target_token2idx.npy', allow_pickle=True).item()\n",
    "target_idx2token = np.load(vocab_dir + 'target_idx2token.npy', allow_pickle=True)\n",
    "print(f'Input vocab size: {len(input_token2idx)}')\n",
    "print(f'Target vocab size: {len(target_token2idx)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "18 <START>\n16 16\n"
     ]
    }
   ],
   "source": [
    "# quick check\n",
    "print(target_token2idx['<START>'], target_idx2token[18])\n",
    "print(input_token2idx['<PAD>'], target_token2idx['<PAD>'])"
   ]
  },
  {
   "source": [
    "Rewrite encoder is functional api"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_SIZE = 2048 # Размерность скрытого состояния LSTM\n",
    "EMB_SIZE = 256 # размерность эмбеддингов (и для входных и для выходных цепочек)\n",
    "ATT_UNITS = 2048 # attention units\n",
    "INPUT_VOCAB_SIZE = len(input_token2idx)\n",
    "max_enc_seq_length = 15 # fixed due to attention mechanics\n",
    "\n",
    "enc_input = tf.keras.Input(shape=(max_enc_seq_length,), dtype=tf.int32, name='encoder_input')\n",
    "masking = tf.keras.layers.Masking(mask_value=input_token2idx['<PAD>'])\n",
    "embed = tf.keras.layers.Embedding(INPUT_VOCAB_SIZE, EMB_SIZE)\n",
    "lstm1 = tf.keras.layers.LSTM(H_SIZE, return_sequences=True, return_state=True)\n",
    "lstm1 = tf.keras.layers.Bidirectional(lstm1, merge_mode='sum', name='enc_out')\n",
    "\n",
    "out = masking(enc_input)\n",
    "out = embed(out)\n",
    "out, h_f, c_f, h_b, c_b = lstm1(out)\n",
    "h1 = tf.keras.layers.Add(name='h_output')([h_f, h_b])\n",
    "c1 = tf.keras.layers.Add(name='c_output')([c_f, c_b])\n",
    "\n",
    "encoder = tf.keras.Model(inputs=enc_input, outputs=[out, h1, c1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nencoder_input (InputLayer)      [(None, 15)]         0                                            \n__________________________________________________________________________________________________\nmasking (Masking)               (None, 15)           0           encoder_input[0][0]              \n__________________________________________________________________________________________________\nembedding (Embedding)           (None, 15, 256)      4380928     masking[0][0]                    \n__________________________________________________________________________________________________\nenc_out (Bidirectional)         [(None, 15, 2048), ( 37765120    embedding[0][0]                  \n__________________________________________________________________________________________________\nh_output (Add)                  (None, 2048)         0           enc_out[0][1]                    \n                                                                 enc_out[0][3]                    \n__________________________________________________________________________________________________\nc_output (Add)                  (None, 2048)         0           enc_out[0][2]                    \n                                                                 enc_out[0][4]                    \n==================================================================================================\nTotal params: 42,146,048\nTrainable params: 42,146,048\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "source": [
    "Тестирование инференса модели (и инициализация весов)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Input: (1, 15)\noutputs: (1, 15, 2048), (1, 2048), (1, 2048)\n"
     ]
    }
   ],
   "source": [
    "input_seq = tf.constant([[6925, 9, 4773, 11, 7169, 677, 17008, 21, 16, 16, 16, 16, 16, 16, 16]])\n",
    "# hidden = encoder.initialize_hidden_state(batch_sz=1) \n",
    "enc_out, h_out, c_out = encoder(input_seq)\n",
    "print(f'Input: {input_seq.shape}')\n",
    "# print(f'starting states: ({hidden[0].shape}, {hidden[1].shape}, {hidden[2].shape}, {hidden[3].shape})')\n",
    "print(f'outputs: {enc_out.shape}, {h_out.shape}, {c_out.shape}')"
   ]
  },
  {
   "source": [
    "Загрузка весов из обученнего энкодера"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x7f3847c8bf10>,\n",
       " <tensorflow.python.keras.layers.core.Masking at 0x7f38477a2e80>,\n",
       " <tensorflow.python.keras.layers.embeddings.Embedding at 0x7f3847f5edc0>,\n",
       " <tensorflow.python.keras.layers.wrappers.Bidirectional at 0x7f3847eeaf70>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f3848162340>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f3847f574c0>]"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "encoder.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embeding layer's weights\n",
    "weights = np.load(enc_dir + 'encoder_embed.npy')\n",
    "encoder.layers[2].set_weights([weights])\n",
    "\n",
    "# load LSTM's weights\n",
    "file_names = [enc_dir + f'encoder_lstm_{i}.npy' for i in range(6)]\n",
    "weights = [np.load(file_name) for file_name in file_names]\n",
    "encoder.layers[3].set_weights(weights)"
   ]
  },
  {
   "source": [
    "Проверка работоспособности загруженной saved_model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: ./Chat-bot/saved_models/encoder_saved/1/assets\n",
      "INFO:tensorflow:Assets written to: ./Chat-bot/saved_models/encoder_saved/1/assets\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "path = './Chat-bot/saved_models/encoder_saved/1'\n",
    "encoder.save(path)\n",
    "model = tf.keras.models.load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\nTrue\nTrue\n"
     ]
    }
   ],
   "source": [
    "# check every tensor in model outputs if it matches original encoder\n",
    "for t1, t2 in zip(encoder(input_seq), model(input_seq)):\n",
    "    print(tf.math.reduce_all(tf.equal(t1, t2)).numpy())\n",
    "del model"
   ]
  },
  {
   "source": [
    "Создадим класс Декодера с вниманием и проинициализируем его"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECODER\n",
    "TARGET_VOCAB_SIZE = len(target_token2idx)\n",
    "# input declaration\n",
    "x = tf.keras.Input(shape=(1, ), name='decoder_input')\n",
    "h_input = tf.keras.Input(shape=(H_SIZE, ), name='h_input')\n",
    "c_input = tf.keras.Input(shape=(H_SIZE, ), name='c_input')\n",
    "enc_output = tf.keras.Input(shape=(max_enc_seq_length, H_SIZE), name='encoder_output')\n",
    "\n",
    "# layers declaration\n",
    "dec_masking = tf.keras.layers.Masking(mask_value=target_token2idx['<PAD>'])\n",
    "dec_embed = tf.keras.layers.Embedding(TARGET_VOCAB_SIZE, EMB_SIZE)\n",
    "dec_lstm1 = tf.keras.layers.LSTM(H_SIZE, return_sequences=True, return_state=True)\n",
    "dec_fc = tf.keras.layers.Dense(TARGET_VOCAB_SIZE, name='decoder_output')\n",
    "att_W1 = tf.keras.layers.Dense(ATT_UNITS, name='att_W1')\n",
    "att_W2 = tf.keras.layers.Dense(ATT_UNITS, name='att_W2')\n",
    "att_V = tf.keras.layers.Dense(1, name='att_V')\n",
    "\n",
    "# attention logic \n",
    "query_with_time_axis = tf.expand_dims(h_input, 1)\n",
    "score = att_V(tf.nn.tanh(\n",
    "            att_W1(query_with_time_axis) + att_W2(enc_output)))\n",
    "attention_weights = tf.nn.softmax(score, axis=1)\n",
    "context_vector = attention_weights * enc_output\n",
    "context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "# decoder logic\n",
    "out = dec_masking(x)\n",
    "out = dec_embed(out)\n",
    "out = tf.concat([tf.expand_dims(context_vector, 1), out], axis=-1)\n",
    "out, h1, c1 = dec_lstm1(out, initial_state=(h_input, c_input))\n",
    "out = tf.reshape(out, (-1, out.shape[2]))\n",
    "out = dec_fc(out)\n",
    "\n",
    "# just to name outputs\n",
    "h_out = tf.keras.layers.Lambda(lambda x: x, name='h_output')(h1)\n",
    "c_out = tf.keras.layers.Lambda(lambda x: x, name='c_output')(c1)\n",
    "\n",
    "# create decoder model\n",
    "decoder = tf.keras.Model(inputs=[x, h_input, c_input, enc_output], outputs=[out, h_out, c_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nh_input (InputLayer)            [(None, 2048)]       0                                            \n__________________________________________________________________________________________________\ntf.expand_dims (TFOpLambda)     (None, 1, 2048)      0           h_input[0][0]                    \n__________________________________________________________________________________________________\nencoder_output (InputLayer)     [(None, 15, 2048)]   0                                            \n__________________________________________________________________________________________________\natt_W1 (Dense)                  (None, 1, 2048)      4196352     tf.expand_dims[0][0]             \n__________________________________________________________________________________________________\natt_W2 (Dense)                  (None, 15, 2048)     4196352     encoder_output[0][0]             \n__________________________________________________________________________________________________\ntf.__operators__.add (TFOpLambd (None, 15, 2048)     0           att_W1[0][0]                     \n                                                                 att_W2[0][0]                     \n__________________________________________________________________________________________________\ntf.math.tanh (TFOpLambda)       (None, 15, 2048)     0           tf.__operators__.add[0][0]       \n__________________________________________________________________________________________________\natt_V (Dense)                   (None, 15, 1)        2049        tf.math.tanh[0][0]               \n__________________________________________________________________________________________________\ntf.nn.softmax (TFOpLambda)      (None, 15, 1)        0           att_V[0][0]                      \n__________________________________________________________________________________________________\ntf.math.multiply (TFOpLambda)   (None, 15, 2048)     0           tf.nn.softmax[0][0]              \n                                                                 encoder_output[0][0]             \n__________________________________________________________________________________________________\ndecoder_input (InputLayer)      [(None, 1)]          0                                            \n__________________________________________________________________________________________________\ntf.math.reduce_sum (TFOpLambda) (None, 2048)         0           tf.math.multiply[0][0]           \n__________________________________________________________________________________________________\nmasking_1 (Masking)             (None, 1)            0           decoder_input[0][0]              \n__________________________________________________________________________________________________\ntf.expand_dims_1 (TFOpLambda)   (None, 1, 2048)      0           tf.math.reduce_sum[0][0]         \n__________________________________________________________________________________________________\nembedding_1 (Embedding)         (None, 1, 256)       4413184     masking_1[0][0]                  \n__________________________________________________________________________________________________\ntf.concat (TFOpLambda)          (None, 1, 2304)      0           tf.expand_dims_1[0][0]           \n                                                                 embedding_1[0][0]                \n__________________________________________________________________________________________________\nc_input (InputLayer)            [(None, 2048)]       0                                            \n__________________________________________________________________________________________________\nlstm_1 (LSTM)                   [(None, 1, 2048), (N 35659776    tf.concat[0][0]                  \n                                                                 h_input[0][0]                    \n                                                                 c_input[0][0]                    \n__________________________________________________________________________________________________\ntf.reshape (TFOpLambda)         (None, 2048)         0           lstm_1[0][0]                     \n__________________________________________________________________________________________________\ndecoder_output (Dense)          (None, 17239)        35322711    tf.reshape[0][0]                 \n__________________________________________________________________________________________________\nh_output (Lambda)               (None, 2048)         0           lstm_1[0][1]                     \n__________________________________________________________________________________________________\nc_output (Lambda)               (None, 2048)         0           lstm_1[0][2]                     \n==================================================================================================\nTotal params: 83,790,424\nTrainable params: 83,790,424\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 17239) dtype=float32 (created by layer 'decoder_output')>,\n",
       " <KerasTensor: shape=(None, 2048) dtype=float32 (created by layer 'h_output')>,\n",
       " <KerasTensor: shape=(None, 2048) dtype=float32 (created by layer 'c_output')>]"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "# check output names\n",
    "decoder.outputs"
   ]
  },
  {
   "source": [
    "Запускаем енкодер и декодер в связке (инициализация весов декодера)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "input_seq = tf.constant([[6925, 9, 4773, 11, 7169, 677, 17008, 21, 16, 16, 16, 16, 16, 16, 16]])\n",
    "# hidden = encoder.initialize_hidden_state(batch_sz=1) # all zeros initial state\n",
    "enc_out, h_out, c_out = encoder(input_seq)\n",
    "\n",
    "dec_input = tf.expand_dims([18], 0) # target_token2idx['<START>'] = 18\n",
    "\n",
    "predictions, h_out, c_out = decoder([dec_input, h_out, c_out, enc_out])\n",
    "predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "print('argmax prediction:', predicted_id)\n",
    "print(f'Encoder outputs: {enc_out.shape}, {h_out.shape}, {c_out.shape}')\n",
    "print ('Decoder outputs: {}, {}, {}'.format(predictions.shape, h_out.shape, c_out.shape))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 91,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "argmax prediction: 10358\nEncoder outputs: (1, 15, 2048), (1, 2048), (1, 2048)\nDecoder outputs: (1, 17239), (1, 2048), (1, 2048)\n"
     ]
    }
   ]
  },
  {
   "source": [
    "Загружаем веса обученного декодера"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " 0: h_input               <class 'tensorflow.python.keras.engine.input_layer.InputLayer'>\n 1: tf.expand_dims        <class 'tensorflow.python.keras.layers.core.TFOpLambda'>\n 2: encoder_output        <class 'tensorflow.python.keras.engine.input_layer.InputLayer'>\n 3: att_W1                <class 'tensorflow.python.keras.layers.core.Dense'>\n 4: att_W2                <class 'tensorflow.python.keras.layers.core.Dense'>\n 5: tf.__operators__.add  <class 'tensorflow.python.keras.layers.core.TFOpLambda'>\n 6: tf.math.tanh          <class 'tensorflow.python.keras.layers.core.TFOpLambda'>\n 7: att_V                 <class 'tensorflow.python.keras.layers.core.Dense'>\n 8: tf.nn.softmax         <class 'tensorflow.python.keras.layers.core.TFOpLambda'>\n 9: tf.math.multiply      <class 'tensorflow.python.keras.layers.core.TFOpLambda'>\n10: decoder_input         <class 'tensorflow.python.keras.engine.input_layer.InputLayer'>\n11: tf.math.reduce_sum    <class 'tensorflow.python.keras.layers.core.TFOpLambda'>\n12: masking_1             <class 'tensorflow.python.keras.layers.core.Masking'>\n13: tf.expand_dims_1      <class 'tensorflow.python.keras.layers.core.TFOpLambda'>\n14: embedding_1           <class 'tensorflow.python.keras.layers.embeddings.Embedding'>\n15: tf.concat             <class 'tensorflow.python.keras.layers.core.TFOpLambda'>\n16: c_input               <class 'tensorflow.python.keras.engine.input_layer.InputLayer'>\n17: lstm_1                <class 'tensorflow.python.keras.layers.recurrent_v2.LSTM'>\n18: tf.reshape            <class 'tensorflow.python.keras.layers.core.TFOpLambda'>\n19: decoder_output        <class 'tensorflow.python.keras.layers.core.Dense'>\n20: h_output              <class 'tensorflow.python.keras.layers.core.Lambda'>\n21: c_output              <class 'tensorflow.python.keras.layers.core.Lambda'>\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(decoder.layers):\n",
    "    print(f'{i:2}: {layer.name:22}{layer.__class__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embeding layer's weights\n",
    "weights = np.load(dec_dir + 'decoder_embed.npy')\n",
    "decoder.layers[14].set_weights([weights])\n",
    "\n",
    "# load LSTM's weights\n",
    "file_names = [dec_dir + f'decoder_lstm_{i}.npy' for i in range(3)]\n",
    "weights = [np.load(file_name) for file_name in file_names]\n",
    "decoder.layers[17].set_weights(weights)\n",
    "\n",
    "# load decoder Dense weights\n",
    "file_names = [dec_dir + f'decoder_fc_{i}.npy' for i in range(2)]\n",
    "weights = [np.load(file_name) for file_name in file_names]\n",
    "decoder.layers[19].set_weights(weights)\n",
    "\n",
    "# load attention.W1 Dense weights\n",
    "file_names = [dec_dir + f'decoder_attW1_{i}.npy' for i in range(2)]\n",
    "weights = [np.load(file_name) for file_name in file_names]\n",
    "decoder.layers[3].set_weights(weights)\n",
    "\n",
    "# load attention.W2 Dense weights\n",
    "file_names = [dec_dir + f'decoder_attW2_{i}.npy' for i in range(2)]\n",
    "weights = [np.load(file_name) for file_name in file_names]\n",
    "decoder.layers[4].set_weights(weights)\n",
    "\n",
    "# load attention.V Dense weights\n",
    "file_names = [dec_dir + f'decoder_attV_{i}.npy' for i in range(2)]\n",
    "weights = [np.load(file_name) for file_name in file_names]\n",
    "decoder.layers[7].set_weights(weights)"
   ]
  },
  {
   "source": [
    "### Проверяем, что декодер сохраняется и остается работоспособным после загрузки"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_9_layer_call_fn, lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_9_layer_call_fn, lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: ./Chat-bot/saved_models/decoder_saved/1/assets\n",
      "INFO:tensorflow:Assets written to: ./Chat-bot/saved_models/decoder_saved/1/assets\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "path = './Chat-bot/saved_models/decoder_saved/1'\n",
    "decoder.save(path)\n",
    "model = tf.keras.models.load_model(path)\n",
    "# model([dec_input, h_out, c_out, enc_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\nTrue\nTrue\n"
     ]
    }
   ],
   "source": [
    "# check every tensor in model outputs if it matches original encoder\n",
    "data = [dec_input, h_out, c_out, enc_out]\n",
    "for t1, t2 in zip(decoder(data), model(data)):\n",
    "    print(tf.math.reduce_all(tf.equal(t1, t2)).numpy())\n",
    "del model"
   ]
  },
  {
   "source": [
    "Запуск инференса chat-bot для токена <START> на тестовом предложении"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10358\n"
     ]
    }
   ],
   "source": [
    "input_seq = np.array([[6925, 9, 4773, 11, 7169, 677, 17008, 21, 16, 16, 16, 16, 16, 16, 16]])\n",
    "\n",
    "# Подготовка данных для HTTP запроса\n",
    "encoder_outputs = encoder_inference(input_seq)\n",
    "\n",
    "enc_out = encoder_outputs['enc_out']\n",
    "h_out = encoder_outputs['h_output']\n",
    "c_out = encoder_outputs['c_output']\n",
    "dec_input = [[target_token2idx['<START>']]] # token <START>\n",
    "\n",
    "decoder_outputs = decoder_inference(dec_input, h_out, c_out, enc_out)\n",
    "\n",
    "dec_out = np.array(decoder_outputs['decoder_output'])\n",
    "print(np.argmax(dec_out))\n"
   ]
  },
  {
   "source": [
    "Предсказание подели из TF_serving совпадает с предсканием модели при запуске в связке (см. инициализация весов декодера)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'no particular reason . . . nice . . . '"
      ]
     },
     "metadata": {},
     "execution_count": 179
    }
   ],
   "source": [
    "input_seq = np.array([[6925, 9, 4773, 11, 7169, 677, 17008, 21, 16, 16, 16, 16, 16, 16, 16]])\n",
    "result = ''\n",
    "# Подготовка данных для HTTP запроса\n",
    "encoder_outputs = encoder_inference(input_seq)\n",
    "\n",
    "enc_out = encoder_outputs['enc_out']\n",
    "h_out = encoder_outputs['h_output']\n",
    "c_out = encoder_outputs['c_output']\n",
    "dec_input = [[target_token2idx['<START>']]] # token <START>\n",
    "\n",
    "# limit max output length to avoid cycled output. \n",
    "# Model was trained on max decoder length = 16.\n",
    "for _ in range(16): \n",
    "\n",
    "    decoder_outputs = decoder_inference(dec_input, h_out, c_out, enc_out)\n",
    "    predictions = np.array(decoder_outputs['decoder_output'])\n",
    "    h_out = decoder_outputs['h_output']\n",
    "    c_out = decoder_outputs['c_output']\n",
    "\n",
    "    temperature = 1.0\n",
    "    predictions = predictions[0] / temperature # predictions - logits, less logits -> less probability difference\n",
    "    pred_softmax = np.exp(predictions)\n",
    "    pred_softmax /= np.sum(pred_softmax)\n",
    "\n",
    "    predicted_id = np.random.choice(range(TARGET_VOCAB_SIZE), p=pred_softmax)\n",
    "    if target_idx2token[predicted_id] == '<END>':\n",
    "        break\n",
    "\n",
    "    result += target_idx2token[predicted_id] + ' '\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = [[int(predicted_id)]]\n",
    "\n",
    "result"
   ]
  }
 ]
}